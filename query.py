# -*- coding: utf-8 -*-
import argparse
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from bs4 import BeautifulSoup
import time
import json
import re
from datetime import datetime
from openpyxl import Workbook, load_workbook
from openpyxl.styles import Font, Alignment
import os

CITY_LABELS = {
    'hgh': 'æ­å·',
    'sha': 'ä¸Šæµ·',
    'pek': 'åŒ—äº¬',
    'can': 'å¹¿å·',
    'szx': 'æ·±åœ³',
    'ctu': 'æˆéƒ½',
    'akl': 'å¥¥å…‹å…°',
    'syd': 'æ‚‰å°¼',
    'mel': 'å¢¨å°”æœ¬',
}

def log_print(msg):
    """å¸¦æ—¶é—´æˆ³çš„æ‰“å°å‡½æ•°"""
    timestamp = datetime.now().strftime("%Y/%m/%d %H:%M:%S")
    print(f"{timestamp} {msg}")

class CTrip_FlightScraper:
    def __init__(self, headless=True, debug=False):
        # åˆå§‹åŒ–æµè§ˆå™¨
        options = webdriver.ChromeOptions()
        
        if headless:
            # å¯ç”¨æ— å¤´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£
            options.add_argument('--headless')
        
        # åçˆ¬è™«å¯¹ç­–
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--start-maximized')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-plugins')
        options.add_argument('--disable-images')  # ç¦ç”¨å›¾ç‰‡åŠ è½½ï¼ŒåŠ å¿«é€Ÿåº¦
        
        # ä¼ªè£…æˆçœŸå®æµè§ˆå™¨
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        options.add_argument('--accept-lang=zh-CN,zh;q=0.9,en;q=0.8')
        
        # ç¦ç”¨Blinkç‰¹æ€§è¯†åˆ«
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ç®¡ç† ChromeDriver
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)
        self.debug = debug
        
        # è®¾ç½®éšå¼ç­‰å¾…
        self.driver.implicitly_wait(10)
        
    def scrape_flights(self, url, direct_only=True):
        """
        çˆ¬å–æºç¨‹ç½‘èˆªç­ä¿¡æ¯
        :param url: æºç¨‹èˆªç­æŸ¥è¯¢é“¾æ¥
        :return: èˆªç­åˆ—è¡¨
        """
        try:
            log_print(f"æ­£åœ¨è®¿é—®é“¾æ¥: {url}")
            log_print("è¯·ç­‰å¾…ï¼Œé¡µé¢åŠ è½½ä¸­...")
            
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            self.driver.set_page_load_timeout(30)
            
            self.driver.get(url)
            
            # å…ˆç­‰å¾…ä»»ä½•å†…å®¹åŠ è½½
            time.sleep(5)
            
            # å°è¯•å¤šä¸ªç­‰å¾…ç­–ç•¥
            try:
                log_print("å°è¯•ç­‰å¾…èˆªç­é¡¹å‡ºç°...")
                WebDriverWait(self.driver, 15).until(
                    EC.presence_of_all_elements_located((By.CLASS_NAME, "item-inner"))
                )
                log_print("âœ“ èˆªç­é¡¹å·²åŠ è½½")
            except:
                try:
                    log_print("å°è¯•ç­‰å¾…productå…ƒç´ ...")
                    WebDriverWait(self.driver, 10).until(
                        EC.presence_of_all_elements_located((By.CLASS_NAME, "product"))
                    )
                    log_print("âœ“ productå…ƒç´ å·²åŠ è½½")
                except:
                    log_print("âš  æœªèƒ½ç­‰å¾…åˆ°é¢„æœŸçš„èˆªç­å…ƒç´ ")
            
            # é¢å¤–ç­‰å¾…ç¡®ä¿åŠ¨æ€å†…å®¹åŠ è½½å®Œæ¯•
            time.sleep(5)
            
            # è·å–é¡µé¢æºä»£ç 
            page_source = self.driver.page_source
            
            if self.debug or len(page_source) < 1000:
                # ä¿å­˜é¡µé¢æºç ä¾›è°ƒè¯•
                debug_file = "debug_page.html"
                with open(debug_file, 'w', encoding='utf-8') as f:
                    f.write(page_source)
                log_print(f"âœ“ é¡µé¢æºç å·²ä¿å­˜åˆ° {debug_file} (å¤§å°: {len(page_source)} å­—èŠ‚)")
            
            if len(page_source) < 100:
                log_print("âŒ è·å–é¡µé¢æºä»£ç å¤±è´¥ï¼Œé¡µé¢è¿‡å°")
                return []
            
            soup = BeautifulSoup(page_source, 'html.parser')
            
            flights = []
            
            # ä½¿ç”¨å¤šä¸ªé€‰æ‹©å™¨å°è¯•æŸ¥æ‰¾èˆªç­é¡¹
            selectors = [
                ('div', {'class': 'item-inner'}),
                ('div', {'class': 'product'}),
                ('div', {'class': 'flight-item'}),
                ('div', {'class': 'search-item'}),
                ('div', {'class': 'item'}),
            ]
            
            flight_items = []
            for tag, attrs in selectors:
                flight_items = soup.find_all(tag, attrs=attrs)
                if flight_items:
                    log_print(f"âœ“ ä½¿ç”¨é€‰æ‹©å™¨ {attrs} æ‰¾åˆ° {len(flight_items)} æ¡è®°å½•")
                    break
            
            if not flight_items:
                log_print("âŒ æœªæ‰¾åˆ°ä»»ä½•èˆªç­é¡¹")
                # å°è¯•æŸ¥çœ‹é¡µé¢ä¸­æ˜¯å¦æœ‰erroræˆ–æç¤ºä¿¡æ¯
                error_elem = soup.find('div', class_='error')
                if error_elem:
                    log_print(f"é¡µé¢æç¤º: {error_elem.get_text()}")
                return []
            
            log_print(f"âœ“ æ‰¾åˆ° {len(flight_items)} æ¡èˆªç­ä¿¡æ¯")
            
            for idx, item in enumerate(flight_items, 1):
                try:
                    # è¿‡æ»¤ç›´é£èˆªç­
                    flight_info = self.parse_flight_item(item, target_direct=direct_only)
                    if flight_info:
                        flights.append(flight_info)
                        log_print(f"  âœ“ æˆåŠŸè§£æèˆªç­ {idx}")
                except Exception as e:
                    if self.debug:
                        log_print(f"  âš  è§£æèˆªç­ {idx} å‡ºé”™: {e}")
                    continue
            
            return flights
            
        except Exception as e:
            log_print(f"âŒ çˆ¬å–èˆªç­ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
        finally:
            log_print("æ­£åœ¨å…³é—­æµè§ˆå™¨...")
            try:
                self.driver.quit()
            except:
                pass
    
    def parse_flight_item(self, item, target_flight_no=None, target_direct=True):
        """
        è§£æå•ä¸ªèˆªç­é¡¹ï¼Œå¯é€‰è¿‡æ»¤ç›®æ ‡èˆªç­æˆ–ç›´é£
        :param item: èˆªç­å…ƒç´ 
        :param target_flight_no: ç›®æ ‡èˆªç­å·
        :param target_direct: æ˜¯å¦ä»…ä¿ç•™ç›´é£
        """
        try:
            flight_info = {}
            
            # æå–æ–‡æœ¬ä¸HTML
            item_text = item.get_text(" ", strip=True)
            item_html = str(item)

            # èˆªç­å·ï¼šæŠ“å–æ‰€æœ‰åŒ¹é…ï¼Œç›´é£åªä¿ç•™å•æ®µèˆªç­
            flight_no_matches = re.findall(r'([A-Z]{2}\d{2,4})', item_html)
            if not flight_no_matches:
                flight_no_matches = re.findall(r'([A-Z]{2}\d{2,4})', item_text)
            if flight_no_matches:
                flight_info['flight_number'] = flight_no_matches[0]
                # å¤šä¸ªèˆªç­å·æ„å‘³ç€ä¸­è½¬/è”ç¨‹
                if target_direct and len(set(flight_no_matches)) > 1:
                    return None

            # å¦‚æœæŒ‡å®šäº†ç›®æ ‡èˆªç­å·ï¼Œåˆ™è¿›è¡Œè¿‡æ»¤
            if target_flight_no and flight_info.get('flight_number'):
                if target_flight_no.upper() not in flight_info['flight_number'].upper():
                    return None

            # ç›´é£è¿‡æ»¤ï¼šæ’é™¤æ˜æ˜¾å«ä¸­è½¬/ç»åœçš„èˆªç­
            if target_direct:
                stop_keywords = ['ç»åœ', 'ä¸­è½¬', 'è½¬æœº', 'è”ç¨‹', 'å«ä¸­è½¬', 'åœç•™']
                if any(k in item_text for k in stop_keywords):
                    return None

            # èˆªç©ºå…¬å¸ï¼šä»æ–‡æœ¬ä¸­æŠ“å–â€œXXèˆªç©ºâ€æˆ–å«â€œèˆªç©ºâ€çš„ç‰‡æ®µ
            airline_match = re.search(r'([\u4e00-\u9fa5]{2,6}èˆªç©º)', item_text)
            if airline_match:
                flight_info['airline'] = airline_match.group(1)

            # å‡ºå‘/åˆ°è¾¾æ—¶é—´ (HH:MM)
            time_matches = re.findall(r'(\d{1,2}):(\d{2})', item_text)
            if target_direct and len(time_matches) > 2:
                # å¤šäºä¸¤ç»„æ—¶é—´é€šå¸¸æ˜¯ä¸­è½¬
                return None
            if len(time_matches) >= 2:
                flight_info['departure_time'] = f"{time_matches[0][0]}:{time_matches[0][1]}"
                flight_info['arrival_time'] = f"{time_matches[1][0]}:{time_matches[1][1]}"

            # é£è¡Œæ—¶é•¿ (xxå°æ—¶xxåˆ†)
            duration_match = re.search(r'(\d+)å°æ—¶(\d+)åˆ†', item_text)
            if duration_match:
                flight_info['duration'] = f"{duration_match.group(1)}h{duration_match.group(2)}m"

            # ä»·æ ¼ï¼šåŒ¹é…åˆç†èŒƒå›´
            price_matches = re.findall(r'Â¥?\s*(\d+)', item_text)
            if price_matches:
                price_values = []
                for price_str in price_matches:
                    try:
                        price_int = int(price_str)
                        if 1000 <= price_int <= 50000:  # è¿‡æ»¤æ‰ä½ä»·è¯¯è¯†åˆ«ï¼ˆå¦‚ç¨è´¹ã€åºå·ï¼‰
                            price_values.append(price_int)
                    except ValueError:
                        continue
                if price_values:
                    flight_info['price'] = str(min(price_values))  # å–æœ€å°çš„åˆè§„ä»·æ ¼

            # è¿”å›åŒ…å«ä»·æ ¼æˆ–èˆªç­å·çš„ç»“æœ
            if flight_info.get('price') or flight_info.get('flight_number'):
                return flight_info
            return None
            
        except Exception as e:
            log_print(f"  âœ— è§£æå•ä¸ªèˆªç­å‡ºé”™: {e}")
            return None

def save_flights_to_file(flights, filename='flights.json'):
    """
    å°†èˆªç­ä¿¡æ¯ä¿å­˜åˆ°JSONæ–‡ä»¶
    """
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(flights, f, ensure_ascii=False, indent=2)
    log_print(f"èˆªç­ä¿¡æ¯å·²ä¿å­˜åˆ° {filename}")


def save_flights_to_excel(flights, dep_city_code, arr_city_code, dep_date, filename='flights_history.xlsx'):
    """
    å°†èˆªç­ä¿¡æ¯ä¿å­˜åˆ°Excelæ–‡ä»¶ï¼ˆæ¯ä¸ªèˆªç­å•ç‹¬ä¸€ä¸ªsheetï¼šåŸå¸‚å¯¹_æ—¥æœŸ_èˆªç©ºå…¬å¸_èˆªç­å·ï¼‰
    """
    query_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    dep_city_label = city_name(dep_city_code)
    arr_city_label = city_name(arr_city_code)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(filename):
        wb = load_workbook(filename)
    else:
        wb = Workbook()
        # åˆ é™¤é»˜è®¤çš„Sheet
        if 'Sheet' in wb.sheetnames:
            wb.remove(wb['Sheet'])
    
    # ä¸ºæ¯ä¸ªèˆªç­åˆ›å»ºå•ç‹¬çš„sheet
    for flight in flights:
        airline = flight.get('airline', 'æœªçŸ¥èˆªç©º').replace('èˆªç©º', '')
        flight_no = flight.get('flight_number', 'N/A')
        
        # ç”Ÿæˆsheetåç§°ï¼šåŸå¸‚å¯¹_æ—¥æœŸ_èˆªç©ºå…¬å¸_èˆªç­å·
        sheet_name = f"{dep_city_label}-{arr_city_label}_{dep_date}_{airline}_{flight_no}"
        
        # Excel sheetåç§°é•¿åº¦é™åˆ¶ä¸º31ä¸ªå­—ç¬¦
        if len(sheet_name) > 31:
            sheet_name = f"{dep_city_label}-{arr_city_label}_{airline}_{flight_no}"[:31]
        
        # æ£€æŸ¥sheetæ˜¯å¦å­˜åœ¨
        if sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
        else:
            ws = wb.create_sheet(sheet_name)
            
            # åˆ›å»ºè¡¨å¤´
            headers = ['æŸ¥è¯¢æ—¶é—´', 'å‡ºå‘åŸå¸‚', 'ç›®çš„åœ°', 'å‡ºå‘æ—¥æœŸ', 'èˆªç©ºå…¬å¸', 'èˆªç­å·', 
                       'å‡ºå‘æ—¶é—´', 'åˆ°è¾¾æ—¶é—´', 'é£è¡Œæ—¶é•¿', 'ä»·æ ¼(Â¥)']
            ws.append(headers)
            
            # è®¾ç½®è¡¨å¤´æ ·å¼
            for cell in ws[1]:
                cell.font = Font(bold=True)
                cell.alignment = Alignment(horizontal='center')
        
        # æ·»åŠ æ•°æ®è¡Œ
        row = [
            query_time,
            dep_city_label,
            arr_city_label,
            dep_date,
            flight.get('airline', 'N/A'),
            flight_no,
            flight.get('departure_time', 'N/A'),
            flight.get('arrival_time', 'N/A'),
            flight.get('duration', 'N/A'),
            flight.get('price', 'N/A')
        ]
        ws.append(row)
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[column_letter].width = adjusted_width
    
    wb.save(filename)
    log_print(f"âœ“ èˆªç­ä¿¡æ¯å·²ä¿å­˜åˆ° {filename}ï¼ˆå…± {len(flights)} ä¸ªsheetï¼‰")

def display_flights(flights, dep_date, dep_city_code="hgh", arr_city_code="akl"):
    """
    æ˜¾ç¤ºèˆªç­ä¿¡æ¯ - ç›´é£èˆªç­
    """
    dep_city_label = city_name(dep_city_code)
    arr_city_label = city_name(arr_city_code)
    
    if not flights:
        log_print(f"\nâŒ æœªæ‰¾åˆ°{dep_city_label} â†’ {arr_city_label}ç›´é£èˆªç­")
        log_print("å¯èƒ½åŸå› ï¼š")
        log_print("  1. è¯¥æ—¥æœŸæ²¡æœ‰ç›´é£èˆªç­")
        log_print("  2. ç½‘ç«™åçˆ¬è™«ä¿æŠ¤")
        log_print("  3. ç½‘ç»œè¿æ¥é—®é¢˜")
        return

    log_print("\n" + "="*80)
    log_print(f"{dep_city_label} â†’ {arr_city_label} ç›´é£èˆªç­ï¼ˆ{dep_date}ï¼‰")
    log_print("="*80)
    log_print(f"{'èˆªç©ºå…¬å¸':<15} {'èˆªç­å·':<10} {'å‡ºå‘':<8} {'åˆ°è¾¾':<8} {'æ—¶é•¿':<8} {'ä»·æ ¼':<12}")
    log_print("-"*80)
    
    for idx, flight in enumerate(flights, 1):
        log_print(f"{flight.get('airline', 'N/A'):<15} "
              f"{flight.get('flight_number', 'N/A'):<10} "
              f"{flight.get('departure_time', 'N/A'):<8} "
              f"{flight.get('arrival_time', 'N/A'):<8} "
              f"{flight.get('duration', 'N/A'):<8} "
              f"Â¥ {flight.get('price', 'N/A'):<10}")
    
    log_print("="*80)
    log_print(f"âœ“ æ‰¾åˆ° {len(flights)} ç­ç›´é£èˆªç­\n")


def build_url(dep_city="hgh", arr_city="akl", dep_date="2026-09-25"):
    return (
        f"https://flights.ctrip.com/online/list/oneway-{dep_city}-{arr_city}?"
        f"depdate={dep_date}&cabin=y_s&adult=1&child=0&infant=0"
    )


def city_name(code: str) -> str:
    return CITY_LABELS.get(code.lower(), code.upper())

# è°ƒç”¨ç¤ºä¾‹ï¼š.\.venv\Scripts\python.exe .\query.py --from sha --to akl --date 2026-09-25
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æŸ¥è¯¢ç›´é£èˆªç­")
    parser.add_argument("--from", dest="from_city", default="hgh",
                        help="å‡ºå‘åŸå¸‚ä»£ç ï¼Œå¦‚ hgh(æ­å·)ã€sha(ä¸Šæµ·)")
    parser.add_argument("--to", dest="to_city", default="akl",
                        help="åˆ°è¾¾åŸå¸‚ä»£ç ï¼Œå¦‚ akl(å¥¥å…‹å…°)ã€syd(æ‚‰å°¼)")
    parser.add_argument("--date", dest="dep_date", default=datetime.now().strftime("%Y-%m-%d"),
                        help="å‡ºå‘æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©")
    parser.add_argument("--headless", dest="headless", action="store_true", default=True,
                        help="å¯ç”¨æ— å¤´æ¨¡å¼ï¼Œé»˜è®¤å¼€å¯")
    parser.add_argument("--no-headless", dest="headless", action="store_false",
                        help="å…³é—­æ— å¤´æ¨¡å¼ï¼Œæ˜¾ç¤ºæµè§ˆå™¨çª—å£")
    parser.add_argument("--debug", action="store_true", default=False,
                        help="ä¿å­˜è°ƒè¯•é¡µé¢æºç ")
    args = parser.parse_args()

    dep_city = args.from_city.strip().lower()
    arr_city = args.to_city.strip().lower()
    
    url = build_url(dep_city=dep_city, arr_city=arr_city, dep_date=args.dep_date)
    dep_label = city_name(dep_city)
    arr_label = city_name(arr_city)
    
    log_print("\n" + "="*80)
    log_print(f"{dep_label} â†’ {arr_label} ç›´é£èˆªç­æŸ¥è¯¢")
    log_print("="*80)
    log_print(f"å‡ºå‘æ—¥æœŸ: {args.dep_date}")
    log_print(f"å‡ºå‘åœ°: {dep_label} ({dep_city.upper()})")
    log_print(f"ç›®çš„åœ°: {arr_label} ({arr_city.upper()})")
    log_print("-" * 80)
    
    scraper = CTrip_FlightScraper(headless=args.headless, debug=args.debug)
    flights = scraper.scrape_flights(url, direct_only=True)
    display_flights(flights, dep_date=args.dep_date, dep_city_code=dep_city, arr_city_code=arr_city)
    
    if flights:
        save_flights_to_file(flights, filename=f"flights_{dep_city}_{arr_city}_{args.dep_date}.json")
        save_flights_to_excel(flights, dep_city, arr_city, args.dep_date)
    else:
        log_print("âš  æœªä¿å­˜ä»»ä½•èˆªç­ä¿¡æ¯")
        log_print("ğŸ’¡ å»ºè®®: å·²ä¿å­˜é¡µé¢æºç åˆ° debug_page.htmlï¼Œè¯·æŸ¥çœ‹é¡µé¢ç»“æ„æ˜¯å¦æ”¹å˜")

